{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPw0b9n3FJIIVfLMv7oW8rC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62Q67IcFbKlh","executionInfo":{"status":"ok","timestamp":1743109560322,"user_tz":-120,"elapsed":12034,"user":{"displayName":"Azza abdelaziz","userId":"08770813708774899615"}},"outputId":"3aaaf50f-d609-4bd5-af68-68929a9606d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Attention Scores:\n"," tensor([[10.2736,  9.4016,  9.9675,  6.4928,  4.0413,  8.3439],\n","        [ 8.4427,  7.7643,  8.3759,  5.2816,  3.3521,  7.0908],\n","        [ 9.4734,  8.6789,  9.2920,  5.9536,  3.7407,  7.8319],\n","        [ 6.7727,  6.2261,  6.6487,  4.2571,  2.6787,  5.5668],\n","        [ 3.3511,  3.0612,  3.2873,  2.1081,  1.3209,  2.7987],\n","        [ 8.3468,  7.6366,  8.2187,  5.2155,  3.2977,  6.8989]])\n","\n","Attention Weights after Softmax:\n"," tensor([[0.4302, 0.1799, 0.3168, 0.0098, 0.0008, 0.0625],\n","        [0.3636, 0.1845, 0.3401, 0.0154, 0.0022, 0.0941],\n","        [0.3980, 0.1798, 0.3320, 0.0118, 0.0013, 0.0771],\n","        [0.3498, 0.2025, 0.3090, 0.0283, 0.0058, 0.1047],\n","        [0.2716, 0.2033, 0.2548, 0.0784, 0.0357, 0.1563],\n","        [0.3764, 0.1850, 0.3312, 0.0164, 0.0024, 0.0885]])\n","\n","Final Output after Attention:\n"," tensor([[1.1273, 1.4218, 2.6927, 1.0964, 1.9576, 0.7871],\n","        [1.1281, 1.4258, 2.6568, 1.0865, 1.9241, 0.7646],\n","        [1.1278, 1.4246, 2.6778, 1.0932, 1.9430, 0.7766],\n","        [1.1251, 1.4152, 2.6230, 1.0677, 1.9009, 0.7560],\n","        [1.1007, 1.3603, 2.4962, 1.0100, 1.8171, 0.7173],\n","        [1.1274, 1.4232, 2.6603, 1.0862, 1.9287, 0.7685]])\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","\n","tokens = [\"What\", \"are\", \"the\", \"symptoms\", \"of\", \"diabetes\"]\n","vocab_size = len(tokens)\n","\n","embedding_dim = 6\n","torch.manual_seed(42)\n","word_embeddings = torch.rand(vocab_size, embedding_dim)\n","\n","W_Q = torch.rand(embedding_dim, embedding_dim)\n","W_K = torch.rand(embedding_dim, embedding_dim)\n","W_V = torch.rand(embedding_dim, embedding_dim)\n","\n","Q = word_embeddings @ W_Q\n","K = word_embeddings @ W_K\n","V = word_embeddings @ W_V\n","\n","d_k = embedding_dim ** 0.5\n","attention_scores = (Q @ K.T) / d_k\n","\n","attention_weights = F.softmax(attention_scores, dim=-1)\n","attention_output = attention_weights @ V\n","\n","print(\"Attention Scores:\\n\", attention_scores)\n","print(\"\\nAttention Weights after Softmax:\\n\", attention_weights)\n","print(\"\\nFinal Output after Attention:\\n\", attention_output)"]}]}